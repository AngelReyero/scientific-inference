{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class LOCI:\n",
    "    def __init__(self, estimator, random_state=None, loss=None, n_jobs=1):\n",
    "        self.estimator = estimator\n",
    "        self.random_state = random_state\n",
    "        self.loss = loss\n",
    "        self.n_jobs = n_jobs\n",
    "        self.feature_names_ = None\n",
    "        self.X_train_ = None\n",
    "        self.y_train_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train_ = X\n",
    "        self.y_train_ = y\n",
    "        self.feature_names_ = X.columns\n",
    "        return self\n",
    "\n",
    "    def _score_single_feature(self, j, X_test, y_test, v0):\n",
    "        fname = self.feature_names_[j]\n",
    "        model_j = clone(self.estimator)\n",
    "        model_j.fit(self.X_train_[[fname]], self.y_train_)\n",
    "        preds_j = model_j.predict(X_test[[fname]])\n",
    "        vj = self.loss(y_test, preds_j)\n",
    "        return fname, v0 - vj\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        if self.X_train_ is None:\n",
    "            raise ValueError(\"You must call `fit` before `score`.\")\n",
    "\n",
    "        # Baseline: constant (mean) model\n",
    "        dummy = DummyRegressor(strategy=\"mean\")\n",
    "        dummy.fit(self.X_train_, self.y_train_)\n",
    "        pred_dummy = dummy.predict(np.zeros((len(X_test), 1)))  # doesn't use features\n",
    "        v0 = self.loss(y_test, pred_dummy)\n",
    "\n",
    "        # LOCI: leave-one-covariate-in\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._score_single_feature)(j, X_test, y_test, v0)\n",
    "            for j in range(X_test.shape[1])\n",
    "        )\n",
    "\n",
    "        return dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCI Importances:\n",
      " {'age': -270.82926799915003, 'sex': 27.756080827185542, 'bmi': 1230.2753625796322, 'bp': -23.115972397773476, 's1': -2365.93678873304, 's2': -2575.9084327976316, 's3': 205.40949575640116, 's4': 872.8721525349347, 's5': 1225.332414583554, 's6': 528.2932637845697}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_diabetes()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create LOCI object\n",
    "loci = LOCI(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    random_state=42,\n",
    "    loss=mean_squared_error,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "loci.fit(X_train, y_train)\n",
    "loci_importance = loci.score(X_test, y_test)\n",
    "\n",
    "print(\"LOCI Importances:\\n\", loci_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -270.829268  ,    27.75608083,  1230.27536258,   -23.1159724 ,\n",
       "       -2365.93678873, -2575.9084328 ,   205.40949576,   872.87215253,\n",
       "        1225.33241458,   528.29326378])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(loci_importance.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def toep (d, rho=0.6):\n",
    "  return np.array([[ (rho)**abs(i-j) for i in range(d)]for j in range(d)])\n",
    "\n",
    "def theoretical_curve(y_method, j, correlation,p, beta=[2, 1]):\n",
    "    \"\"\"\n",
    "    Computes the theoretical value for a coordinate `j` based on the specified method.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_method : str\n",
    "        The method used for computation. Can be either 'lin' (linear) or 'nonlin' (nonlinear).\n",
    "    j : int\n",
    "        The coordinate index for which the theoretical value is computed.\n",
    "    correlation : float\n",
    "        The correlation coefficient.\n",
    "    p : int\n",
    "        The dimension of the Toeplitz matrix used in the nonlinear case.\n",
    "    beta : list, optional\n",
    "        Coefficients used in the linear case, default is [2, 1].\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The theoretical value for the given coordinate `j`.\n",
    "    \"\"\"\n",
    "    if y_method == 'lin':\n",
    "        return beta[j]**2*(1-correlation**2)\n",
    "    elif y_method == 'fixed_poly':\n",
    "        if j==0:\n",
    "            mat=toep(p, correlation)\n",
    "            sigma_0=mat[0]\n",
    "            sigma_0=np.delete(sigma_0, 0)\n",
    "            inv=np.delete(mat, 0, axis=0)\n",
    "            inv=np.delete(inv, 0, axis=1)\n",
    "            inv=np.linalg.inv(inv)\n",
    "            return (correlation-np.dot(np.dot(sigma_0,inv), sigma_0.T))\n",
    "        elif j==1:\n",
    "            mat=toep(p, correlation)\n",
    "            sigma_j=mat[j]\n",
    "            sigma_j=np.delete(sigma_j, j)\n",
    "            inv=np.delete(mat, j, axis=0)\n",
    "            inv=np.delete(inv, j, axis=1)\n",
    "            inv=np.linalg.inv(inv)\n",
    "            return (4*(correlation-np.dot(np.dot(sigma_j,inv), sigma_j.T)))\n",
    "        elif j==4:# var(X²) = 2sigma⁴+4sigma²mu²\n",
    "            mat=toep(p, correlation)\n",
    "            sigma_j=mat[j]\n",
    "            sigma_j=np.delete(sigma_j, j)\n",
    "            inv=np.delete(mat, j, axis=0)\n",
    "            inv=np.delete(inv, j, axis=1)\n",
    "            inv=np.linalg.inv(inv)\n",
    "            cond_var= (correlation-np.dot(np.dot(sigma_j,inv), sigma_j.T))\n",
    "            mu = np.zeros(p)\n",
    "            Sigma = toep(p, correlation)  # covariance matrix of X\n",
    "            rng = np.random.default_rng(0)\n",
    "            X = rng.multivariate_normal(mu, Sigma, size=(10000))\n",
    "            X_minus_j = np.delete(X, j, axis=1)\n",
    "            mn=np.dot(X_minus_j, np.dot(sigma_j,inv))\n",
    "            return np.mean(2*cond_var**2+4*cond_var*mn**2)\n",
    "        elif j==7 or j==8:# sigma²*sigma_cond²\n",
    "            mat=toep(p, correlation)\n",
    "            sigma_j=mat[j]\n",
    "            sigma_j=np.delete(sigma_j, j)\n",
    "            inv=np.delete(mat, j, axis=0)\n",
    "            inv=np.delete(inv, j, axis=1)\n",
    "            inv=np.linalg.inv(inv)\n",
    "            return correlation**2*(correlation-np.dot(np.dot(sigma_j,inv), sigma_j.T))\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True values\n",
    "true_values = {}\n",
    "for j in range(10):\n",
    "    true_values['V'+str(j)]=theoretical_curve('fixed_poly', j, 0.6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V0': np.float64(0.23999999999999994),\n",
       " 'V1': np.float64(0.2823529411764705),\n",
       " 'V2': 0,\n",
       " 'V3': 0,\n",
       " 'V4': np.float64(0.15918653482012055),\n",
       " 'V5': 0,\n",
       " 'V6': 0,\n",
       " 'V7': np.float64(0.025411764705882342),\n",
       " 'V8': np.float64(0.02541176470588238),\n",
       " 'V9': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.36000000000000004)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat=toep(10, 0.6)\n",
    "sigma_0=mat[0]\n",
    "sigma_0=np.delete(sigma_0, 0)\n",
    "inv=np.delete(mat, 0, axis=0)\n",
    "inv=np.delete(inv, 0, axis=1)\n",
    "inv=np.linalg.inv(inv)\n",
    "(np.dot(np.dot(sigma_0,inv), sigma_0.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.6       , 0.36      , 0.216     , 0.1296    ,\n",
       "       0.07776   , 0.046656  , 0.0279936 , 0.01679616, 0.0100777 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6       , 0.36      , 0.216     , 0.1296    , 0.07776   ,\n",
       "       0.046656  , 0.0279936 , 0.01679616, 0.0100777 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
